{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f7445b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the essential libraries into jupyter notebook \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.metrics import Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88dc1073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building parameters for the images\n",
    "    \n",
    "image_rows, image_columns = 150, 150\n",
    "num_classes = 2\n",
    "batch_size = 32\n",
    "\n",
    "# Setting the directories for cats and dogs datasets\n",
    "\n",
    "Dogs_dir = '/Users/user/Desktop/ML_Project/PetImages/Dog'\n",
    "Cats_dir = '/Users/user/Desktop/ML_Project/PetImages/Cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70e5fa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analising Dog images\n",
    "\n",
    "Dogs_images = []\n",
    "m = 0\n",
    "for n in os.listdir(Dogs_dir):\n",
    "    image = cv2.imread(os.path.join(Dogs_dir, n), cv2.IMREAD_GRAYSCALE)\n",
    "    if image is not None:\n",
    "        Dogs_images.append(image)\n",
    "        m += 1;\n",
    "        if m >1000:\n",
    "            break;\n",
    "\n",
    "# Analising cat images\n",
    "\n",
    "Cats_images = []\n",
    "m = 0;\n",
    "for n in os.listdir(Cats_dir):\n",
    "    image = cv2.imread(os.path.join(Cats_dir, n), cv2.IMREAD_GRAYSCALE)\n",
    "    if image is not None:\n",
    "        Cats_images.append(image)\n",
    "        m +=1;\n",
    "        if m >1000:\n",
    "            break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abea1cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the proportion of images to same size\n",
    "\n",
    "Dogs_images = [cv2.resize(n, (image_rows, image_columns)) for n in Dogs_images]\n",
    "Cats_images = [cv2.resize(n, (image_rows, image_columns)) for n in Cats_images]\n",
    "\n",
    "# Translating images to arrays\n",
    "\n",
    "Dogs_images = np.array(Dogs_images)\n",
    "Cats_images = np.array(Cats_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc984433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designing labels and combining two images sets\n",
    "\n",
    "X = np.concatenate((Dogs_images, Cats_images), axis=0)\n",
    "Y = np.concatenate((np.zeros(len(Dogs_images)), np.ones(len(Cats_images))), axis=0)\n",
    "\n",
    "# Breaking train and test data sets to split\n",
    "\n",
    "X_train, X_test, Y_train,Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f50be0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By normalizing enchanting the data and encoding the labels\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], image_rows, image_columns, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], image_rows, image_columns, 1)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "Y_train = np_utils.to_categorical(Y_train, num_classes)\n",
    "Y_test = np_utils.to_categorical(Y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3d8f7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designing CNN deep learning model with all the layers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), padding='same', input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Arranging the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy', tf.keras.metrics.Precision() ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f75fa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data accretion\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "981f7275",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19860\\3804672967.py:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 63s 1s/step - loss: 1.5258 - accuracy: 0.5296 - precision: 0.5296 - val_loss: 0.6923 - val_accuracy: 0.4892 - val_precision: 0.4892\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 60s 1s/step - loss: 0.7458 - accuracy: 0.5201 - precision: 0.5201 - val_loss: 0.6868 - val_accuracy: 0.4908 - val_precision: 0.4908\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 60s 1s/step - loss: 0.7090 - accuracy: 0.5157 - precision: 0.5157 - val_loss: 0.6848 - val_accuracy: 0.5125 - val_precision: 0.5125\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 60s 1s/step - loss: 0.6914 - accuracy: 0.5245 - precision: 0.5245 - val_loss: 0.6851 - val_accuracy: 0.5208 - val_precision: 0.5208\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 60s 1s/step - loss: 0.6850 - accuracy: 0.5566 - precision: 0.5566 - val_loss: 1.1596 - val_accuracy: 0.5092 - val_precision: 0.5092\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 60s 1s/step - loss: 0.7069 - accuracy: 0.5625 - precision: 0.5625 - val_loss: 0.6699 - val_accuracy: 0.6007 - val_precision: 0.6007\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 60s 1s/step - loss: 0.6730 - accuracy: 0.5807 - precision: 0.5807 - val_loss: 0.6665 - val_accuracy: 0.6123 - val_precision: 0.6123\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 59s 1s/step - loss: 0.6905 - accuracy: 0.5902 - precision: 0.5902 - val_loss: 0.6513 - val_accuracy: 0.6722 - val_precision: 0.6722\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 59s 1s/step - loss: 0.6728 - accuracy: 0.6004 - precision: 0.6004 - val_loss: 0.6375 - val_accuracy: 0.6572 - val_precision: 0.6572\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 177s 4s/step - loss: 0.6903 - accuracy: 0.6114 - precision: 0.6114 - val_loss: 0.6290 - val_accuracy: 0.6489 - val_precision: 0.6489\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 49s 1s/step - loss: 0.6724 - accuracy: 0.6019 - precision: 0.6019 - val_loss: 0.6540 - val_accuracy: 0.6240 - val_precision: 0.6240\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 48s 1s/step - loss: 0.6649 - accuracy: 0.6209 - precision: 0.6209 - val_loss: 0.6267 - val_accuracy: 0.6656 - val_precision: 0.6656\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 60s 1s/step - loss: 0.6749 - accuracy: 0.6318 - precision: 0.6318 - val_loss: 0.6311 - val_accuracy: 0.6689 - val_precision: 0.6689\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 60s 1s/step - loss: 0.6735 - accuracy: 0.6158 - precision: 0.6158 - val_loss: 0.6174 - val_accuracy: 0.6539 - val_precision: 0.6539\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 59s 1s/step - loss: 0.6718 - accuracy: 0.6194 - precision: 0.6194 - val_loss: 0.6178 - val_accuracy: 0.6889 - val_precision: 0.6889\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 61s 1s/step - loss: 0.6485 - accuracy: 0.6348 - precision: 0.6348 - val_loss: 0.6196 - val_accuracy: 0.6656 - val_precision: 0.6656\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 60s 1s/step - loss: 0.6514 - accuracy: 0.6472 - precision: 0.6472 - val_loss: 0.6091 - val_accuracy: 0.6672 - val_precision: 0.6672\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 59s 1s/step - loss: 0.6533 - accuracy: 0.6304 - precision: 0.6304 - val_loss: 0.6086 - val_accuracy: 0.6589 - val_precision: 0.6589\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 59s 1s/step - loss: 0.6433 - accuracy: 0.6406 - precision: 0.6406 - val_loss: 0.5912 - val_accuracy: 0.6872 - val_precision: 0.6872\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 60s 1s/step - loss: 0.6434 - accuracy: 0.6260 - precision: 0.6260 - val_loss: 0.5987 - val_accuracy: 0.6872 - val_precision: 0.6872\n",
      "Test data loss: 0.598701536655426\n",
      "Test data Accuracy: 0.6871880292892456\n",
      "Test data Precision: 0.6871880292892456\n"
     ]
    }
   ],
   "source": [
    "# Arranging the model on the accretion dataset\n",
    "\n",
    "datagen.fit(X_train)\n",
    "history = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
    "steps_per_epoch=len(X_train) // batch_size,\n",
    "epochs=20,\n",
    "validation_data=(X_test, Y_test),\n",
    "validation_steps=len(X_test) // batch_size)\n",
    "\n",
    "# On the test data set estimating the model\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test data loss:', score[0])\n",
    "print('Test data Accuracy:', score[1])\n",
    "print('Test data Precision:', score[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6d2a15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing our deep learning model with the Decision Tree, KNN and, SVM Classifier machine learning models\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8635a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixing axis\n",
    "\n",
    "Y_train = Y_train.argmax(axis=1)\n",
    "Y_test = Y_test.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33c9dd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree, KNN, SVM Classifier models \n",
    "\n",
    "DT_clf = DecisionTreeClassifier()\n",
    "KNN_clf = KNeighborsClassifier()\n",
    "SVM_clf = SVC()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b466547c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Installing the models on train dataset\n",
    "\n",
    "DT_clf.fit(X_train.reshape(X_train.shape[0], image_rows*image_columns), Y_train)\n",
    "KNN_clf.fit(X_train.reshape(X_train.shape[0], image_rows*image_columns), Y_train)\n",
    "SVM_clf.fit(X_train.reshape(X_train.shape[0], image_rows*image_columns), Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfd4577f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valuate the models on the test data\n",
    "\n",
    "DT_preds = DT_clf.predict(X_test.reshape(X_test.shape[0], image_rows*image_columns))\n",
    "KNN_preds = KNN_clf.predict(X_test.reshape(X_test.shape[0], image_rows*image_columns))\n",
    "SVM_preds = SVM_clf.predict(X_test.reshape(X_test.shape[0], image_rows*image_columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "404a0346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the accuracies of all the traditional machine learning models\n",
    "\n",
    "DT_accuracy = accuracy_score(Y_test, DT_preds)\n",
    "KNN_accuracy = accuracy_score(Y_test, KNN_preds)\n",
    "SVM_accuracy = accuracy_score(Y_test, SVM_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "189f2a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the precision of all the traditional machine learning models\n",
    "\n",
    "DT_precision = precision_score(Y_test, DT_preds, average='weighted')\n",
    "KNN_precision = precision_score(Y_test, KNN_preds, average='weighted')\n",
    "SVM_precision = precision_score(Y_test, SVM_preds, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "515c7b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the loss of all the traditional machine learning models\n",
    "\n",
    "DT_loss = DT_clf.score(X_test.reshape(X_test.shape[0], image_rows*image_columns), Y_test)\n",
    "KNN_loss = KNN_clf.score(X_test.reshape(X_test.shape[0], image_rows*image_columns), Y_test)\n",
    "SVM_loss = SVM_clf.score(X_test.reshape(X_test.shape[0], image_rows*image_columns), Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1fdb1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Comparing the performance of deep learning model with Decision tree, KNN and, SVM machine learning models\n",
      "The accuracy of CNN model: 0.6871880292892456 vs Decision Tree: 0.5474209650582362 vs KNN: 0.5640599001663894 vs SVM: 0.5873544093178037\n",
      "The Precision of CNN model: 0.6871880292892456 vs Decision Tree: 0.5483944332914681 vs KNN: 0.5658030443776083 vs SVM: 0.5880780305373614\n",
      "The Loss of CNN model: 0.598701536655426 vs Decision Tree: 0.5474209650582362 vs KNN: 0.5640599001663894 vs SVM: 0.5873544093178037\n"
     ]
    }
   ],
   "source": [
    "# Comparing CNN model with all other traditional models\n",
    "\n",
    "print(' Comparing the performance of deep learning model with Decision tree, KNN and, SVM machine learning models')\n",
    "print(f'The accuracy of CNN model: {score[1]} vs Decision Tree: {DT_accuracy} vs KNN: {KNN_accuracy} vs SVM: {SVM_accuracy}')\n",
    "print(f'The Precision of CNN model: {score[2]} vs Decision Tree: {DT_precision} vs KNN: {KNN_precision} vs SVM: {SVM_precision}')\n",
    "print(f'The Loss of CNN model: {score[0]} vs Decision Tree: {DT_loss} vs KNN: {KNN_loss} vs SVM: {SVM_loss}')\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf08c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
